## 데이터 수집 및 전환 

### 🖋 빅데이터 수집 기법 
    포털사이트 및 소셜 네트워크 등의 디지털 가상 공간에서 실시간으로 생성되는 HTML,XML 형태의 모든 데이터를 수집하기 위한 기법이다.

1. 정형 데이터 수집 기법 
* ETL
    * Extract Transform Lead의 약어
    * 다양한 데이터의 원천으로 수집한 데이터를 데이터 웨어하우스와 데이터 마트로 원 데이터를 이동시키기 위해 사용하는 추출,변환, 적재 프로세스 및 기술을 의미함
* FTP 
    * File Transfer Protocol 의 약자  
    * TCP/IP 프로토콜을 통해 원거리에 있는 서버와 클라이언트 사이의 파일 전송을 위한 프로토콜
클라이언트가 데이터를 수신 받을 포트를 먼저 알려주는 Active FTP 방식과 서버가 임의로 알려준 포트에 클라이언트가 접근하는 Passive FTP 방식이 있음
* API  
    * Application Programming Interface 의 약자
    * 응용프로그램에서 사용할 수 있도록 운영체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 았게 만든 인터페이스
* Sqoop  
    * 구조화된 관계형 데이터베이스와 아파치 하둡 간의 대용량 데이터들을 효율적으로 변환하여 주는 명령 줄 인터페이스(Command-Line-Interface) 애플리케이션
장애 허용 능력 및 병렬처리 가능   

### 2. 반정형 데이터 수집
    반정형 데이터 수집 기법으로 가장 많이 활용되눈 것은 로그 수집기로서, 이르는 끊임없이 생성되는 대향의 데이터를 연속적으로 처리하기에 적합한 도구(Scribe , Flume ,Chukwa)
* Scribe
    * 페이스북에서 개발한 실시간 스트리밍 로그 데이터 수집 애플리케이션
    * 분산된 서버에서 발생하는 데이터를 중앙 집중 서버로 전송하는 방식을 이용함 
    * 네트워크와 시스템의 장애를 해결하기 위해 고안된 애플리케이션으로 확장성과 신뢰성을 목표로 함
* Flume
    * 분산 환경에서 대량의 로그 데이터를 효과적으로 수집하고 합친 후 효율적으로 전송할 수 있는 서비스
    * 클러스터 환경에서 장애에 쉽게 대처 가능하고 로그 유실에 대한 신뢰 수준을 상황에 맞게 변경함으로써 신뢰성 있는 데이터 수집을 수행함
    * 다양한 장비에서 수집되눈 로그 파일 데이터를 하둡 분산 파일 시스템과 같은 중앙 저장소에 저장하는 로깅 시스템 구축 시 적합함 
    * 핵심 목표는 신뢰성,확장성,운영가능성,가용성 
* Chukwa
    * 분산된 노드를의 다양한 로그 데이터를 수집하고 수집된 데이터를 HDFS에 저장하고 분석하기 위한 시스템
    * 주요 수집 로그는 모니터링 로그,하둡 로그,응용프로그램 로그등이며 데라바이트 다누이 이상의 로그 데이터를 실시간으로 모니터링 가능함

### 3. 비정형 데이터 수집
    비정형 데이터 수집 기법은 크롤링, 스크래피, 아프치 카프카, RSS,Open Api 등이 있다. 최근에는 스크래피와 아파치 카프카를 많이 사용한다.
* 스크래피
    * 파이썬으로 작성된 오픈소스 웹 크롤링 프레임워크로서, 웹 데이터를 수집
    * API를 이용하여 데이터 추출하거나, 범용 웹 크롤러로 사용이 가능함
* 아파치 카프카
    * 실시간 데이터 피드를 관리하기 위해 높은 처리량 , 낮은 지연시간을 지닌 플랫폼을 제공함 
    * 분산 트랜잭션 로그로 구성되어 있으며, scale-out 방식의 수평 확장이 가능함
    * 비정형 데이터 수집을 쉬해 가장 흔히 활용하는 것은 크롤링으로서,크롤링은 주로 인터넷 상의 여러 웹페이지에서 html 코드 ,문서 들의 데이터를 수집해서 분류하고 저장하는 것이다.
 
### 🖋  데이터 소스에 따른 수집 방법

    데이터 소스의 위치에 따라 내부 데이터와 외부 데이터로 구분할 수 있으며 해당 구분에 따라 다른 방법으로 데이터를 수집할 수 있다.
* 내부 데이터
    * 자체적으로 보유한 내부 파일 시스템,RDBMS,센서 등에 접근하여 수집
    * 대표적인 수집 방법 : ETL 방식
        * Extraction(추출)
        * Transform(변환)
        * Load(적재)
* 외부 데이터
    * 인터넷으로 연결된 외부 데이터 수집 
    * 대표적인 수집 방법 : 크롤링


### 🖋 빅데이터 수집 시스템의 요건

    빅데이터 수집 시스템은 다양한 데이터 원천으로부터 데이터를 수집하기 위해 확장성,안정성,유연성,실시간성의 요건을 확보하여야 한다.
* 확장성
    * 데이터 수집의 대상이 되는 서버는 충분한 확장이 가능
* 안정성
    * 수집된 데이터는 유실 ,변경, 삭제되지 않고 안정적으로 저장
* 유연성
    * 다양한 데이터 원천의 여러 포맷에 적용할 수 있도록 변경이 용이
* 실시간성
    * 수집된 데이터는 실시간으로 반영 
 
### 🖋 빅데이터 수집 절차

1. 수집 대상 선정
* 수집 도메인 추출
* 수집 데이터셋 도출
* 수집 리스트 작성
v수집 대상 부서 파악
2. 수집 계획 수립
* 데이터 제공 여부 협의
* 데이터 유형 및 속성 확인
* 수집 환경 및 표준 파악
* 수집 주기 및 용량 파악
* 수집 연동 및 포맷 파악
* 수집 기술 선정
* 수집 정의서 및 계획서 작성
3. 수집 실행
* 단위 테스트 진행
* 연동 테스트 진행
* 데이터 수집 실행
* 데이터 적재 처리
 
### 📍 수집 대상에 따른 데이터 유형
    빅데이터 수집 시스템의 수집 대상이 되는 데이터는 구조, 시간, 저장 형태 관점에 따라 데이터 유형 구분 가능
 
 
### 📍 일반적인 데이터의 특징
    데이터의 형식을 결정하는 존재론적 특징을 기준으로 데이터를 구분하면 정성적 데이터와 정량적 데이터로 구분할 수 있다.
 
### 📍 구조 관점의 데이터 유형
1. 정형 데이터
* 정형 데이터는 미리 정해 놓은 형식과 구조에 따라 저장되도록 구성된 데이터로 구조적 데이터라고도 한다.
2. 반정형 데이터
* 데이터의 형식과 구조가 변경될 수 있는 데이터로 데이터 내부에 정형 데이터의 스키마에 해당되는 메타데이터를 갖고 있으며 일반적으로 파일 형태로 저장된다.
* 메타 데이터는 데이터의 구조 정보이므로 데이터가 어떤 형태를 가졌는지 파악하는 것이 필요하다.
* Crawling,RSS,FTP, Open API , Flume,Scribe, Chukwa
3. 비정형 데이터
* 스키마가 없음 , 정의된 구조가 없이 정형화 되지 않은 데이터
* 수집 대상은 데이터 세트가 아니라 객체화되어 있는 하나의 데이터이다.
* 언어 분석이 가능한 텍스트 데이터나 이미지,동영상과 같은 멀티미디어 데이터가 대표적인 정형 데이터이다.
* Crawling,RSS,FTP, Open API ,Streaming,Scrapy,Apach

### 📍 시간 관점의 데이터 유형
    데이터를 시간 관점에서 분류하면 실시간 데이터, 비실시간 데이터 또는 배치 데이터의 두 가지 유형으로 나눌 수 있다.
 
* 실시간 데이터
    * 실시간 데이터는 센서 데이터, 시스템 로그, 네트워크 장비로그, 보안 장비 로그,알람 등과 같이 생성된 이후 수 초 ~ 수분 이내에 처리되어야 의미가 있는 현재 데이터를 말한다.
* 비실시간 데이터
    * 비실시간 데이터는 통계, 웹 로그, 서비스 로그 , 구매 정보, 헬스케이 정보 등과 같이 생성된 데이터가 수 시간 또는 수 주 이후에 처리되어야 의미가 있는 과거 데이터를 말한다.
 
### 📍 저장 형태 관점의 데이터 유형
    빅데이터 수집 시스템에서 수집 데이터를 저장하는 형태의 관점에서 분류하면 파일 데이터, 데이터베이스 데이터 ,콘텐츠 데이터, 스트림 데이터 들으로 구분할 수 있다.
 
* 파일 데이터
    * 파일 데이터는 시스템 로그 , 서비스 로그 ,텍스트, 스프레드 시트 등과 같이 파일 형식으로 파일 시스템에 저장되는데이터이며 파일 크기가 대용량이거나 파일 개수가 다수이다.
* 데이터베이스 데이터
    * 데이터베이스 데이터는 데이터의 종류나 성격에 따라 관계형 데이터베이스, NOSQL,인메모리 데이터베이스등에 데이터베이스의 컬럼 또는 테이블등에 저장된 데이터를 말한다.
* 콘텐츠 데이터
    * 콘텐츠 데이터는 텍스트,이미지,오디오,비디오 등과 같이 개별적으로 데이터 객체로 구분될 수 있는 미디어 데이터를 말한다.
* 스트림 데이터
    * 스트림 데이터는 센서 데이터, HTTP 트랜잭션, 알람 등과 같이 네트워크를 통해서 실시간으로 전송되는 데이터를 말한다.

### 🖋 데이터 변환 

### 빅데이터 변환의 이해
    데이터 처리 및 분석을 효율적으로 진행하기 위해서는 데이터의 분석 목적에 따라 데이터를 변환 시킬 필요가 있다.
    데이터 변환은 컴퓨터가 읽을수 있도록 정형 데이터로 바꾸는것을 의미한다.
 
### 데이터 전.후처리 단계

####개념
* 데이터 전처리 : 수집된 데이터를 저장소에 적재하기 위해 데이터 필터링 ,유형 변환 ,정제 등의 기술을 사용하여 데이터 변환하는 단계
* 데이터 후처리 : 저장된 데이터를 분석에 용이하도록 변환,통합,축소 등의 기술을 사용하여 가공하는 단계이다.

#### 고려사항
* 전처리 고려사항
    * 유형 분류시, 분류 기준을 적용할 수 있는 기능 제공
    * 변환에 필요한 알고리즘 혹은 구조를 정의할 수 있는 기능 제공
    * 결과 데이터 저장 기능 제공 
    * 데이터 변환 실패 시 재시도 및 취소할 수 있는 기능 제공
    * 실패 이력 저장 및 해당 내용을 사용자에세 전달하는 기능 제공 
사용자 지정 기준에 맞게 변환 되었는지 확인 기능 제공
* 후처리 고려사항
    * 이상값을 추세에 맞게 변환 또는 추천할 수 있는 기능 제공
    * 집계시 , 데이터 요약 기능 제공
    * 특정 구간에 분포하는 값 추출 등에 대한 확인 기능을 통해 변환 ,패턴, 이벤트를 감시할 수 있는 기능
### 🖋 데이터 변환 기술

* 평활화 (Smooting)
    * 데이터로부터 잡음을 제거하기 위해 데이터 추세에서 벗어나는 값을 변환
* 집계 (Aggregation)
    * 다양한 차원의 방법으로 데이터를 요약함
* 일반화 (Generalization)
    * 특정 구간에 분포하는 값으로 스케일을 변화시킴
* 정규화 (Normalization)
    * 데이터가 정해진 구간 내에 포함되도록 한다.
* 속성 생성 (Attibute/Feature Construction)
    * 데이터 통합을 위해 새로운 속성 및 특징을 만든다.


### 🖋 ETL 프로세스

#### ETL 개념
    ETL은 데이터의 이동 및 변환 절차와 관련된 업계 표준용어이다.ETL 프로세스는 서로 다른 시스템 간의 데이터 공유를 위한 가장 일반적인 형태의 하나이며 기존의 레거시 시스템 환경으로부터 빅데이터를 추출하여 비즈니스 데이터로 변환할 수 있도록 지원한다.
    다양한 데이터의 원천우로부터 추출 및 변환된 데이터를 운영데이터 스토어,데이터웨어하우스,데이터 마트등에 적재하는 작업에서 핵심적인 역할을 한다.
 
#### 🖋 데이터 변환 절차
    비정형 데이터를 정형 데이터로 변환하여 저장할 때 관계형 DBMS을 가장 많이 사용한다.
    비정형 또는 반정형 데이터를 정형 데이터로 변환하는 과정은 다음과 같다.
1. 데이터 구조
2. 수행 코드 정의
3. 프로그램 작성
4. DB 저장
 
