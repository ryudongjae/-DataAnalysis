# 데이터 전처리

## 데이터 전처리란?

로우 데이터에 대한 정제, 데이터 통합 , 데이터 변환 등의 과정을 수행하여 진행하고자 하는 분석에 최적화된 형태로 데이터를 변형하는 과정

### 데이터 전처리의 필요성

분석 목적에 필요한 데이터 확보는 방대한 양의 빅데이터만을 의미하는 것이 아니라 데이터의 질적인 측면까지 동시에 고려해야한다.

1. 데이터의 다양성은 분석 모델의 완성도를 높일 수 있는 등 현실을 반영하는 데이터의 필요를 의미한다.

2. 확보된 데이터가 분석이 가능한 형태로 준비되어야 한다.

## 데이터 전처리 유형

### 📍데이터 정제

결측치를 채워넣고, 잡음이 있는 데이터를 평활화하고, 이상치를 식별하고, 데이터 불일치를 교정하는 작업을 포함한다.

### 📍 결측치

- 결측치는 입력이 누락되어 값이 존재하지 않고 비어있는 값을 의미한다.
- 결측치가 있는 데이터는 정보 손실에 의한 상당한 편의를 야기시킬 수 있고 데이터를 다루고 분석하는 것을 어렵게 만들며 , 분석의 효율성을 감소시킨다.

**결측치 유형**

- 완전 무작위 결측
    - 어떤 변수의 결측치는 관측된 다른 변수들과 아무런 연관이 없아 완전히 핸덤하게 발생한 경우
- 무작위 결측
    - 실제 데이터에서 가장 빈번한 형태로, 어떤 변수의 결측치가 관측된 다른 변수에 영향을 받지만 해당 변수의 비관측값들과는 연관되어 있지 않은 경우를 말한다.
- 비무작위 결측
    - 어떤 변수의 결측치가 완전 무작위 또는 무작위 결측이 아닌 경우이다.

**결측치 처리**

결측치를 처리하는 방법은 크게 단순 대치법과 다중 대치법으로 분류된다.

- 단순 대치법
    - 단순 삭제 (Completes Analysis)
    - 평균 대치법 ( Mean Imputation)
    - 단순확률 대치법 (Single Stochastic Imputation)
- 다중 대치법
    - 다중 대치법은 단순 대치법을 M번 수행하여 M개의 가상적 완전 데이터를 만드는 방법이다.
        1. 대치
        2. 분석
        3. 결합

<aside>
💡 결측치를 포함한 데이터 분석에 사용하기 용이하고, 단순확률 대치법보다는 통계적 추론에 사용된 통계량의 효율성 및 일치성등의 문제를 부분적으로 보완해 준다.

</aside>

**그 외 결측치 처리 방법**

수작업으로 결측값 입력 , 전역상수를 사용한 결측값 입력 , 결측값의 무시 

### 📍 이상치

의도하지 않게 잘못 입력한 경우나 의도하지 않게 입력되었으나 분석 목적에 부합하지 않아 제거해야 하는 경우 등 잘못된 데이터도 있지만 , 의도하지 않은 현상이지만 분석에 포함해야 하는 경우와 의도된 이상값인 경우까지 다양하다.

**이상치 판별**

- 사분위수
    - 사분위수란 데이터 표본을 가장 작은 값부터 가장 큰 값으로 정렬한 후,4등분 했을 때 각 등위에 해당하는 값을 의미한다.
- 정규분포
    - 주어진 데이터의 평균.중앙값.최빈값이 모두 동일한 경우 데이터는 평균을 기준으로 좌우가 대칭인 종모양의 정규분포가 된다.
- 군집화
    - 데이터를 여러 클러스터로 분류한 뒤, 작은 크기의 클러스터나 클러스터 사이의 거리가 너무 먼 경우 해당 클러스터에 속한 관측치를 이상치로 볼 수 있다.

이상치 처리

- 결측 처리 방법
    - 논리적으로 존재할 수 없는 경우 바로 결측 처리한다.
- 극단치 기준 이용 방법
    - 하단,상단 % 이용한 제거법으로 10%절단은 상자그림에서 상하위 5%에 해당되는 데이터를 삭제한다.
- 극단값 절단 방법
    - 상자그림에서 상단과 하단의 각 극단치 경계를 값들과 하한값과 상한값으로 조정한다.

### 📍 데이터 불일치 해결

1. 데이터의 입력설계가 잘못된 경우
2. 입력자 또는 입력장칭의 오류
3. 의도적 오류
4. 데이터의 노후화

이러한 불일치를 발견하기 위해서는 무엇보다 해당 분야의 직무지식이 중요하고 그 외에도 코드 사용에 있어서 데이터 형식이나 표기방식 등의 일관성이 결여된 것은 없는지를 살펴야 한다.

### 📍 필터링

필터링은 방대한 데이터에 조건을 적용하여 분석 목적에 맞는 데이터를 찾아내는 과정이다.하지만 데이터 활용 목적에 맞지 않은 정보를 걸러내거나 항목을 줄여야 할 때 필터링으로 제거하면 가장 간결하고 가독성 좋은 세부 정보를 보다 파악할 수 있다.

### 데이터 통합

서로 다른 원천의 여러 데이터를 결합하거나 서로 다른 데이터들이 호환 가능하도록 통합하는 작업이다.

**데이터 통합 주요 고려사항**

1. 스키마 통합과 개체의 매칭
    1. 서로 다른 소스에서 발견되지만 실제 그 내용이 동일한 항목을 가리키는 경우 이들을 어떻게 대응시킬 것인가 하는 개체 식별의 문제이다.
2. 데이터 중복
    1. 여러 소스에 걸쳐 데이터 값이 중복된 경우 이를 선별하고 중복값을 제거하는 문제이다. 이때 속성 간의 불일치 또는 차원의 명칭 문제가 발생하기도 한다.
3. 하나의 속성에 대해 여러 상충되는 값 
    1. 이는 여러 소스의 데이터를 일관성 있는 하나의 데이터로 합치는 과정에서 일어나는 불일치의 문제이다.

### 데이터 축소

분석에 필요한 변수들만 선택하거나 데이터의 특성을 반영하고 요약변수를 생성하여 분석 대상이 되는 데이터의 차원을 줄이는 작업이다.

원 데이터의 고유한 특성은 손상되지 않도록 최대한 유지하면서 분석에 더욱 효과적일 수 있도록 변수를 선택하거나 요약하는 작업을 포함한다.

### 데이터 변환

변수값에 대해 정규화,표준화 등의 작업을 수행하거나 데이터의 형식을 변환하는 등 분석 알고리즘에 입력할 수 있는 형태로 데이터를 변환하는 작업이다.

데이터 변환 기법

1. 데이터 형식 및 구조 변환
    1. 데이터 분석 목적에 따라 데이터의 형식을 변환하여 사용한다.
2. 데이터 스케일링
    1. 데이터들의 범위가 같아지도록 속성별로 값을 비례적으로 조정하는 과정을 의미한다.
    2. 표준화 → 각 개체들이 평균을 기준으로 얼마나 떨어져 있는지를 나타내는 값으로 변환하는 과정을 의미한다.
    3. 표준화한 후 특정 범위를 벗어난 데이터를 확인하여 이상치 판별에 활용할 수도 있다.
    4. 정규화 → 데이터의 범위를 0과 1사이로 변환하여 데이터의 분포를 조정하는 방법이다.
3. 평활화
    1. 데이터 집합에 존재하는 노이즈로 인해 거칠게 분포된 데이터를 매끄럽게 만드는 방법이다.
4. 비정형 데이터 변화 
    1. 비정형 텍스트 데이터의 경우 단어들의 빈도를 표현하는 방법을 이용하여 정형 데이터로 변환하는 과정을 거쳐서 이미지 분석을 수행한다.